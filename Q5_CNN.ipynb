{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe58e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code reference 1: https://github.com/andreoniriccardo/CNN-from-scratch/tree/main\n",
    "## code reference 2: https://towardsdatascience.com/building-a-convolutional-neural-network-from-scratch-using-numpy-a22808a00a40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d459017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 19:01:40.539380: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-28 19:01:40.578661: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-28 19:01:40.579461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 19:01:41.374661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf ## for loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40da968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "## choose 3000 samples as the training set\n",
    "X_train = X_train[:3000]\n",
    "y_train = y_train[:3000]\n",
    "\n",
    "## choose 500 samples as the validation test\n",
    "X_test = X_test[:500]\n",
    "y_test = y_test[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c549c8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 28, 28), (500, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84c0b4",
   "metadata": {},
   "source": [
    "## build CNN from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1bd0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conv layer\n",
    "class ConvolutionLayer:\n",
    "    def __init__(self, kernel_num, kernel_size):\n",
    "        \"\"\"\n",
    "        Constructor takes as input the number of kernels and their size. I assume only squared filters of size kernel_size x kernel_size\n",
    "        \"\"\"\n",
    "        ## the number of filters\n",
    "        self.kernel_num = kernel_num\n",
    "        ## size of filters\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        # Generate random filters of shape (kernel_num, kernel_size, kernel_size). \n",
    "        # Divide by kernel_size^2 for weight normalization\n",
    "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size**2)\n",
    "\n",
    "    def patches_generator(self, image):\n",
    "        \"\"\"\n",
    "        Divide the input image in patches to be used during convolution.\n",
    "        Yields the tuples containing the patches and their coordinates.\n",
    "        \"\"\"\n",
    "        # Extract image height and width\n",
    "        image_h, image_w = image.shape\n",
    "        self.image = image\n",
    "        \n",
    "        # The number of patches, given a fxf filter is h-f+1 for height and w-f+1 for width\n",
    "        for h in range(image_h-self.kernel_size+1):\n",
    "            for w in range(image_w-self.kernel_size+1):\n",
    "                patch = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
    "                yield patch, h, w\n",
    "    \n",
    "    def forward_prop(self, image):\n",
    "        \"\"\"\n",
    "        Perform forward propagation for the convolutional layer.\n",
    "        \"\"\"\n",
    "        # Extract image height and width\n",
    "        image_h, image_w = image.shape\n",
    "        \n",
    "        # Initialize the shape of the output after convolution\n",
    "        convolution_output = np.zeros((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_num))\n",
    "        # Unpack the generator\n",
    "        for patch, h, w in self.patches_generator(image):\n",
    "            # Perform convolution for each patch\n",
    "            convolution_output[h,w] = np.sum(patch*self.kernels, axis=(1,2))\n",
    "        return convolution_output\n",
    "    \n",
    "    def back_prop(self, dE_dY, alpha):\n",
    "        \"\"\"\n",
    "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
    "        to the kernels' weights.\n",
    "        dE_dY comes from the following layer, typically max pooling layer.\n",
    "        It updates the kernels' weights\n",
    "        \"\"\"\n",
    "        # Initialize gradient of the loss function with respect to the kernel weights\n",
    "        dE_dk = np.zeros(self.kernels.shape)\n",
    "        for patch, h, w in self.patches_generator(self.image):\n",
    "            for f in range(self.kernel_num):\n",
    "                dE_dk[f] += patch * dE_dY[h, w, f]\n",
    "        # Update the filters\n",
    "        self.kernels -= alpha*dE_dk\n",
    "        return dE_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14245484",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pooling layer\n",
    "## the task of the pooling layer is to shrink the input image, which can reduce the number of parameters.\n",
    "class MaxPoolingLayer:\n",
    "    def __init__(self, kernel_size):\n",
    "        \"\"\"\n",
    "        Constructor takes as input the size of the kernel\n",
    "        \"\"\"\n",
    "        ## the shape of filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def patches_generator(self, image):\n",
    "        \"\"\"\n",
    "        Divide the input image in patches to be used during pooling.\n",
    "        Yields the tuples containing the patches and their coordinates.\n",
    "        \"\"\"\n",
    "        # the shape of output after the pooling\n",
    "        output_h = image.shape[0] // self.kernel_size\n",
    "        output_w = image.shape[1] // self.kernel_size\n",
    "        self.image = image\n",
    "        \n",
    "        # yield the portions of the images on which to performn each convolution step\n",
    "        for h in range(output_h):\n",
    "            for w in range(output_w):\n",
    "                patch = image[(h*self.kernel_size):(h*self.kernel_size+self.kernel_size), (w*self.kernel_size):(w*self.kernel_size+self.kernel_size)]\n",
    "                yield patch, h, w\n",
    "\n",
    "    def forward_prop(self, image):\n",
    "        image_h, image_w, num_kernels = image.shape  ## (row, column, # of filters)\n",
    "        \n",
    "        # the shape of the output after pooling\n",
    "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
    "        \n",
    "        ## for each pacth, choose the max value in this patch as the value \n",
    "        for patch, h, w in self.patches_generator(image):\n",
    "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1))\n",
    "        return max_pooling_output\n",
    "\n",
    "    def back_prop(self, dE_dY):\n",
    "        \"\"\"\n",
    "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
    "        to the kernels' weights.\n",
    "        dE_dY comes from the following layer, typically softmax.\n",
    "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
    "        \"\"\"\n",
    "        dE_dk = np.zeros(self.image.shape)\n",
    "        for patch,h,w in self.patches_generator(self.image):\n",
    "            image_h, image_w, num_kernels = patch.shape\n",
    "            max_val = np.amax(patch, axis=(0,1))\n",
    "\n",
    "            for idx_h in range(image_h):\n",
    "                for idx_w in range(image_w):\n",
    "                    for idx_k in range(num_kernels):\n",
    "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
    "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
    "        return dE_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "011d250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## softmax layer\n",
    "class SoftmaxLayer:\n",
    "    \"\"\"\n",
    "    Takes the volume coming from convolutional & pooling layers. It flattens it and it uses it in the next layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_units, output_units):\n",
    "        # Initiallize weights and biases\n",
    "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
    "        self.bias = np.zeros(output_units)\n",
    "\n",
    "    ## forward process\n",
    "    def forward_prop(self, image):\n",
    "        self.original_shape = image.shape # stored for backprop\n",
    "        \n",
    "        # Flatten the image\n",
    "        image_flattened = image.flatten()\n",
    "        self.flattened_input = image_flattened # stored for backprop\n",
    "        \n",
    "        # linear\n",
    "        first_output = np.dot(image_flattened, self.weight) + self.bias\n",
    "        self.output = first_output\n",
    "        \n",
    "        # softmax activation function\n",
    "        softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
    "        return softmax_output\n",
    "\n",
    "    ## back propogation\n",
    "    def back_prop(self, dE_dY, alpha):\n",
    "        for i, gradient in enumerate(dE_dY):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "            transformation_eq = np.exp(self.output)\n",
    "            S_total = np.sum(transformation_eq)\n",
    "\n",
    "            # Compute gradients with respect to output (Z)\n",
    "            # dy/dz\n",
    "            dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
    "            dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
    "\n",
    "            # Compute gradients of output Z with respect to weight, bias, input. \n",
    "            # dz/dw, dz/db, dz/dx\n",
    "            dZ_dw = self.flattened_input\n",
    "            dZ_db = 1\n",
    "            dZ_dX = self.weight\n",
    "\n",
    "            # Gradient of loss with respect ot output\n",
    "            dE_dZ = gradient * dY_dZ\n",
    "\n",
    "            # Gradient of loss with respect to weight, bias, input\n",
    "            dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
    "            dE_db = dE_dZ * dZ_db\n",
    "            dE_dX = dZ_dX @ dE_dZ\n",
    "\n",
    "            # Update parameters\n",
    "            # weight = weight - alpha*de/dw\n",
    "            # bias = bias - alpha*de/db\n",
    "            self.weight -= alpha*dE_dw\n",
    "            self.bias -= alpha*dE_db\n",
    "\n",
    "            return dE_dX.reshape(self.original_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dba04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## forward and backporpagation\n",
    "def CNN_forward(image, label, layers):\n",
    "    ## pixel value from 0-255 to 0-1\n",
    "    output = image/255.\n",
    "    \n",
    "    # forward\n",
    "    for layer in layers:\n",
    "        output = layer.forward_prop(output)\n",
    "    \n",
    "    # Compute loss (cross-entropy) and accuracy\n",
    "    loss = -np.log(output[label])\n",
    "    accuracy = 1 if np.argmax(output) == label else 0\n",
    "    \n",
    "    return output, loss, accuracy\n",
    "\n",
    "def CNN_backprop(gradient, layers, alpha=0.05):\n",
    "    grad_back = gradient\n",
    "    \n",
    "    ## from the last layer to the first layer\n",
    "    for layer in layers[::-1]:\n",
    "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
    "            grad_back = layer.back_prop(grad_back, alpha)\n",
    "        elif type(layer) == MaxPoolingLayer:\n",
    "            grad_back = layer.back_prop(grad_back)\n",
    "    return grad_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b43abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training process\n",
    "\n",
    "def CNN_training(image, label, layers, alpha=0.001):\n",
    "    # Forward step\n",
    "    output, loss, accuracy = CNN_forward(image, label, layers)\n",
    "\n",
    "    # Initial gradient\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[label] = -1/output[label]\n",
    "\n",
    "    # Backprop step\n",
    "    gradient_back = CNN_backprop(gradient, layers, alpha)\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe29ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a validation process\n",
    "def CNN_valid(image, label, layers):\n",
    "    # only contain forward step\n",
    "    output, loss, accuracy = CNN_forward(image, label, layers)\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59afe8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 2.1522890524614615, accuracy 0.398\n",
      "Step 1001. For the last 500 steps: average loss 1.7140629411385266, accuracy 0.694\n",
      "Step 1501. For the last 500 steps: average loss 1.1373485097796012, accuracy 0.776\n",
      "Step 2001. For the last 500 steps: average loss 0.8409783946106144, accuracy 0.798\n",
      "Step 2501. For the last 500 steps: average loss 0.6684464226228302, accuracy 0.852\n",
      "Epoch 1: Training loss 0.09860305292244678, Valid loss 0.14033333333333334, Training accuracy 0.5705851704142173, Valid accuracy 0.5705851704142173\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.47922016721249205, accuracy 0.854\n",
      "Step 1001. For the last 500 steps: average loss 0.45093763602492476, accuracy 0.876\n",
      "Step 1501. For the last 500 steps: average loss 0.41497322097793166, accuracy 0.874\n",
      "Step 2001. For the last 500 steps: average loss 0.3588329558037249, accuracy 0.92\n",
      "Step 2501. For the last 500 steps: average loss 0.4875926946687664, accuracy 0.864\n",
      "Epoch 2: Training loss 0.06578256943622458, Valid loss 0.14666666666666667, Training accuracy 0.3984794097796073, Valid accuracy 0.3984794097796073\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.308270501304095, accuracy 0.91\n",
      "Step 1001. For the last 500 steps: average loss 0.3611049461754823, accuracy 0.89\n",
      "Step 1501. For the last 500 steps: average loss 0.3743626038536816, accuracy 0.878\n",
      "Step 2001. For the last 500 steps: average loss 0.4453444910315297, accuracy 0.88\n",
      "Step 2501. For the last 500 steps: average loss 0.3611430906949632, accuracy 0.89\n",
      "Epoch 3: Training loss 0.05787903558359141, Valid loss 0.14933333333333335, Training accuracy 0.33723520369503085, Valid accuracy 0.33723520369503085\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.3363813088411002, accuracy 0.904\n",
      "Step 1001. For the last 500 steps: average loss 0.39803660616191433, accuracy 0.87\n",
      "Step 1501. For the last 500 steps: average loss 0.2599755944671575, accuracy 0.92\n",
      "Step 2001. For the last 500 steps: average loss 0.33313336837714946, accuracy 0.904\n",
      "Step 2501. For the last 500 steps: average loss 0.37544092595035145, accuracy 0.894\n",
      "Epoch 4: Training loss 0.04707642460137158, Valid loss 0.15133333333333332, Training accuracy 0.30520277595957734, Valid accuracy 0.30520277595957734\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.27510325391793145, accuracy 0.916\n",
      "Step 1001. For the last 500 steps: average loss 0.31081841464175436, accuracy 0.91\n",
      "Step 1501. For the last 500 steps: average loss 0.3315508777265605, accuracy 0.888\n",
      "Step 2001. For the last 500 steps: average loss 0.3495125871366565, accuracy 0.908\n",
      "Step 2501. For the last 500 steps: average loss 0.2584611199674129, accuracy 0.934\n",
      "Epoch 5: Training loss 0.05944971210237826, Valid loss 0.14833333333333334, Training accuracy 0.27923285070059745, Valid accuracy 0.27923285070059745\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.27487132301722683, accuracy 0.91\n",
      "Step 1001. For the last 500 steps: average loss 0.27272724023585276, accuracy 0.914\n",
      "Step 1501. For the last 500 steps: average loss 0.28347863381847616, accuracy 0.91\n",
      "Step 2001. For the last 500 steps: average loss 0.2849393391017383, accuracy 0.926\n",
      "Step 2501. For the last 500 steps: average loss 0.3412289241179987, accuracy 0.89\n",
      "Epoch 6: Training loss 0.05770735120063208, Valid loss 0.14966666666666667, Training accuracy 0.2639835467100404, Valid accuracy 0.2639835467100404\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.25622295987800425, accuracy 0.93\n",
      "Step 1001. For the last 500 steps: average loss 0.2501889956751407, accuracy 0.924\n",
      "Step 1501. For the last 500 steps: average loss 0.3433315587968924, accuracy 0.89\n",
      "Step 2001. For the last 500 steps: average loss 0.3972136580909359, accuracy 0.9\n",
      "Step 2501. For the last 500 steps: average loss 0.2381695407647914, accuracy 0.926\n",
      "Epoch 7: Training loss 0.03960780664688595, Valid loss 0.15566666666666668, Training accuracy 0.25142956873456523, Valid accuracy 0.25142956873456523\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.26055910443112235, accuracy 0.92\n",
      "Step 1001. For the last 500 steps: average loss 0.27740988449314824, accuracy 0.924\n",
      "Step 1501. For the last 500 steps: average loss 0.2583324563303248, accuracy 0.916\n",
      "Step 2001. For the last 500 steps: average loss 0.3435853208231939, accuracy 0.896\n",
      "Step 2501. For the last 500 steps: average loss 0.2535051608927342, accuracy 0.914\n",
      "Epoch 8: Training loss 0.04097538956525229, Valid loss 0.152, Training accuracy 0.24301682788457785, Valid accuracy 0.24301682788457785\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.23778995707553469, accuracy 0.936\n",
      "Step 1001. For the last 500 steps: average loss 0.22275058312932405, accuracy 0.926\n",
      "Step 1501. For the last 500 steps: average loss 0.2254305961250959, accuracy 0.928\n",
      "Step 2001. For the last 500 steps: average loss 0.24186982686022898, accuracy 0.92\n",
      "Step 2501. For the last 500 steps: average loss 0.32117993160213343, accuracy 0.916\n",
      "Epoch 9: Training loss 0.05194949674709621, Valid loss 0.15266666666666667, Training accuracy 0.23704053294510008, Valid accuracy 0.23704053294510008\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.23177473327743933, accuracy 0.934\n",
      "Step 1001. For the last 500 steps: average loss 0.29322225844216815, accuracy 0.918\n",
      "Step 1501. For the last 500 steps: average loss 0.2518321558433804, accuracy 0.916\n",
      "Step 2001. For the last 500 steps: average loss 0.2696127639796086, accuracy 0.918\n",
      "Step 2501. For the last 500 steps: average loss 0.20013978280956177, accuracy 0.944\n",
      "Epoch 10: Training loss 0.041965119466584655, Valid loss 0.154, Training accuracy 0.23127290541286155, Valid accuracy 0.23127290541286155\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.2598874572027271, accuracy 0.92\n",
      "Step 1001. For the last 500 steps: average loss 0.26618037713578613, accuracy 0.92\n",
      "Step 1501. For the last 500 steps: average loss 0.22466312751982714, accuracy 0.94\n",
      "Step 2001. For the last 500 steps: average loss 0.2779456663474611, accuracy 0.926\n",
      "Step 2501. For the last 500 steps: average loss 0.2117305867207731, accuracy 0.934\n",
      "Epoch 11: Training loss 0.03978598249420214, Valid loss 0.15366666666666667, Training accuracy 0.2165917709254397, Valid accuracy 0.2165917709254397\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.22679431856097992, accuracy 0.932\n",
      "Step 1001. For the last 500 steps: average loss 0.2771276184412736, accuracy 0.928\n",
      "Step 1501. For the last 500 steps: average loss 0.20832421972502438, accuracy 0.938\n",
      "Step 2001. For the last 500 steps: average loss 0.236174573833167, accuracy 0.918\n",
      "Step 2501. For the last 500 steps: average loss 0.26512235783715, accuracy 0.918\n",
      "Epoch 12: Training loss 0.03721755930182983, Valid loss 0.15633333333333332, Training accuracy 0.21166048412626998, Valid accuracy 0.21166048412626998\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.21507151559805254, accuracy 0.938\n",
      "Step 1001. For the last 500 steps: average loss 0.24558488028724818, accuracy 0.922\n",
      "Step 1501. For the last 500 steps: average loss 0.23514344474032614, accuracy 0.918\n",
      "Step 2001. For the last 500 steps: average loss 0.22848847268260886, accuracy 0.932\n",
      "Step 2501. For the last 500 steps: average loss 0.28223705292721407, accuracy 0.924\n",
      "Epoch 13: Training loss 0.03125922229884887, Valid loss 0.15766666666666668, Training accuracy 0.2077041486746438, Valid accuracy 0.2077041486746438\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.1849979888305444, accuracy 0.944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1001. For the last 500 steps: average loss 0.25699584978608486, accuracy 0.922\n",
      "Step 1501. For the last 500 steps: average loss 0.18800173462362016, accuracy 0.946\n",
      "Step 2001. For the last 500 steps: average loss 0.25850378092854887, accuracy 0.932\n",
      "Step 2501. For the last 500 steps: average loss 0.205976056332583, accuracy 0.94\n",
      "Epoch 14: Training loss 0.04118274911097427, Valid loss 0.15466666666666667, Training accuracy 0.20651834839792493, Valid accuracy 0.20651834839792493\n",
      "Step 1. For the last 500 steps: average loss 0.0, accuracy 0.0\n",
      "Step 501. For the last 500 steps: average loss 0.19433224100349772, accuracy 0.94\n",
      "Step 1001. For the last 500 steps: average loss 0.1990224730508276, accuracy 0.948\n",
      "Step 1501. For the last 500 steps: average loss 0.2542937225881802, accuracy 0.912\n",
      "Step 2001. For the last 500 steps: average loss 0.2716883563581379, accuracy 0.914\n",
      "Step 2501. For the last 500 steps: average loss 0.18865667548759518, accuracy 0.944\n",
      "Epoch 15: Training loss 0.02992622795806013, Valid loss 0.158, Training accuracy 0.19622384591140116, Valid accuracy 0.19622384591140116\n"
     ]
    }
   ],
   "source": [
    "# Define the network\n",
    "# since filters size is 3x3 and input size is 28x28, so the output of the convolutional layer is 26x26  (28-3+1)\n",
    "layers = [\n",
    "    ConvolutionLayer(16,3), # layer with 16 3x3 filters, output (26,26,16)\n",
    "    MaxPoolingLayer(2), # pooling layer 2x2, output (26/2, 26/2, 16)\n",
    "    SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output\n",
    "    ] \n",
    "\n",
    "train_loss_total = []\n",
    "valid_los_total = []\n",
    "## set 15 epochs \n",
    "for epoch in range(15):\n",
    "    #print('Epoch {} ->'.format(epoch+1))\n",
    "    \n",
    "    # Shuffle training data\n",
    "    permutation = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[permutation]\n",
    "    y_train = y_train[permutation]\n",
    "    \n",
    "    # Training the CNN\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
    "        if i % 500 == 0: # Every 100 examples\n",
    "            print(\"Step {}. For the last 500 steps: average loss {}, accuracy {}\".format(i+1, loss/500, accuracy/500))\n",
    "            loss = 0\n",
    "            accuracy = 0\n",
    "        loss_1, accuracy_1 = CNN_training(image, label, layers)\n",
    "        loss += loss_1\n",
    "        accuracy += accuracy_1\n",
    "        \n",
    "        \n",
    "    ## Add a valid process, and then we can show the loss curve\n",
    "    loss_val = 0\n",
    "    accuracy_val = 0\n",
    "    for i, (image, label) in enumerate(zip(X_test, y_test)):\n",
    "        loss_2, accuracy_2 = CNN_training(image, label, layers)\n",
    "        loss_val += loss_2\n",
    "        accuracy_val += accuracy_2\n",
    "        \n",
    "    ep_loss_train = loss/len(y_train)    \n",
    "    ep_loss_val = loss_val/len(y_test)\n",
    "    \n",
    "    train_loss_total.append(ep_loss_train)\n",
    "    valid_los_total.append(ep_loss_val)\n",
    "    print(\"Epoch {}: Training loss {}, Valid loss {}, Training accuracy {}, Valid accuracy {}\".format(epoch+1, ep_loss_train, accuracy/len(y_train), loss_val/len(y_test), ep_loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d103b8",
   "metadata": {},
   "source": [
    "## plot loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a5fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61fc1cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot loss cruve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx_list = list(range(len(valid_los_total)))\n",
    "\n",
    "#fig = plt.figure()\n",
    "plt.plot(idx_list,train_loss_total,'s-',color = 'r',label=\"Train loss\")  # train curve\n",
    "plt.plot(idx_list,valid_los_total,'o-',color = 'g',label=\"Valid loss\")  # validation curve\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend() \n",
    "plt.title(\"Train-Valid Loss Curve\")\n",
    "#plt.savefig(\"Q5_loss_curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6775d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
